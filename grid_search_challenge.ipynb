{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of sales\n",
    "\n",
    "### Problem Statement\n",
    "This dataset represents sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store are available. The aim is to build a predictive model and find out the sales of each product at a particular store.\n",
    "\n",
    "|Variable|Description|\n",
    "|: ------------- |:-------------|\n",
    "|Item_Identifier|Unique product ID|\n",
    "|Item_Weight|Weight of product|\n",
    "|Item_Fat_Content|Whether the product is low fat or not|\n",
    "|Item_Visibility|The % of total display area of all products in a store allocated to the particular product|\n",
    "|Item_Type|The category to which the product belongs|\n",
    "|Item_MRP|Maximum Retail Price (list price) of the product|\n",
    "|Outlet_Identifier|Unique store ID|\n",
    "|Outlet_Establishment_Year|The year in which store was established|\n",
    "|Outlet_Size|The size of the store in terms of ground area covered|\n",
    "|Outlet_Location_Type|The type of city in which the store is located|\n",
    "|Outlet_Type|Whether the outlet is just a grocery store or some sort of supermarket|\n",
    "|Item_Outlet_Sales|Sales of the product in the particulat store. This is the outcome variable to be predicted.|\n",
    "\n",
    "Please note that the data may have missing values as some stores might not report all the data due to technical glitches. Hence, it will be required to treat them accordingly.\n",
    "\n",
    "\n",
    "\n",
    "### Explore the problem in following stages:\n",
    "\n",
    "1. Hypothesis Generation – understanding the problem better by brainstorming possible factors that can impact the outcome\n",
    "2. Data Exploration – looking at categorical and continuous feature summaries and making inferences about the data.\n",
    "3. Data Cleaning – imputing missing values in the data and checking for outliers\n",
    "4. Feature Engineering – modifying existing variables and creating new ones for analysis\n",
    "5. Model Building – making predictive models on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have covered data preparation and feature engineering two weeks ago. Now, it's time to do some predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "## Task\n",
    "Make a baseline model. Baseline models help us set a benchmark to gauge the performance of our future models. If your new model is below the baseline, something has gone wrong, and you should check your data.\n",
    "\n",
    "To make a baseline model, run a simple regression model without altering the default parameters in sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data_feature_engg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Fat_Content', 'Item_Visibility', 'Item_MRP',\n",
       "       'Outlet_Establishment_Year', 'Outlet_Location_Type',\n",
       "       'Item_Outlet_Sales', 'Item_Weight', 'Outlet_Size', 'misleading',\n",
       "       'Item_Type_Baking Goods', 'Item_Type_Breads', 'Item_Type_Breakfast',\n",
       "       'Item_Type_Canned', 'Item_Type_Dairy', 'Item_Type_Frozen Foods',\n",
       "       'Item_Type_Fruits and Vegetables', 'Item_Type_Hard Drinks',\n",
       "       'Item_Type_Health and Hygiene', 'Item_Type_Household', 'Item_Type_Meat',\n",
       "       'Item_Type_Others', 'Item_Type_Seafood', 'Item_Type_Snack Foods',\n",
       "       'Item_Type_Soft Drinks', 'Item_Type_Starchy Foods',\n",
       "       'Outlet_Type_Grocery Store', 'Outlet_Type_Supermarket Type1',\n",
       "       'Outlet_Type_Supermarket Type2', 'Outlet_Type_Supermarket Type3',\n",
       "       'Item_Identify_Type_DR', 'Item_Identify_Type_FD',\n",
       "       'Item_Identify_Type_NC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>misleading</th>\n",
       "      <th>Item_Type_Baking Goods</th>\n",
       "      <th>...</th>\n",
       "      <th>Item_Type_Snack Foods</th>\n",
       "      <th>Item_Type_Soft Drinks</th>\n",
       "      <th>Item_Type_Starchy Foods</th>\n",
       "      <th>Outlet_Type_Grocery Store</th>\n",
       "      <th>Outlet_Type_Supermarket Type1</th>\n",
       "      <th>Outlet_Type_Supermarket Type2</th>\n",
       "      <th>Outlet_Type_Supermarket Type3</th>\n",
       "      <th>Item_Identify_Type_DR</th>\n",
       "      <th>Item_Identify_Type_FD</th>\n",
       "      <th>Item_Identify_Type_NC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3735.1380</td>\n",
       "      <td>9.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>443.4228</td>\n",
       "      <td>5.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2097.2700</td>\n",
       "      <td>17.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>732.3800</td>\n",
       "      <td>19.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>994.7052</td>\n",
       "      <td>8.93</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Fat_Content  Item_Visibility  Item_MRP  Outlet_Establishment_Year  \\\n",
       "0                 0         0.016047  249.8092                         23   \n",
       "1                 1         0.019278   48.2692                         13   \n",
       "2                 0         0.016760  141.6180                         23   \n",
       "3                 1         0.000000  182.0950                         24   \n",
       "4                 0         0.000000   53.8614                         35   \n",
       "\n",
       "   Outlet_Location_Type  Item_Outlet_Sales  Item_Weight  Outlet_Size  \\\n",
       "0                     0          3735.1380         9.30            1   \n",
       "1                     2           443.4228         5.92            1   \n",
       "2                     0          2097.2700        17.50            1   \n",
       "3                     2           732.3800        19.20            0   \n",
       "4                     2           994.7052         8.93            2   \n",
       "\n",
       "   misleading  Item_Type_Baking Goods  ...  Item_Type_Snack Foods  \\\n",
       "0           0                       0  ...                      0   \n",
       "1           0                       0  ...                      0   \n",
       "2           0                       0  ...                      0   \n",
       "3           0                       0  ...                      0   \n",
       "4           1                       0  ...                      0   \n",
       "\n",
       "   Item_Type_Soft Drinks  Item_Type_Starchy Foods  Outlet_Type_Grocery Store  \\\n",
       "0                      0                        0                          0   \n",
       "1                      1                        0                          0   \n",
       "2                      0                        0                          0   \n",
       "3                      0                        0                          1   \n",
       "4                      0                        0                          0   \n",
       "\n",
       "   Outlet_Type_Supermarket Type1  Outlet_Type_Supermarket Type2  \\\n",
       "0                              1                              0   \n",
       "1                              0                              1   \n",
       "2                              1                              0   \n",
       "3                              0                              0   \n",
       "4                              1                              0   \n",
       "\n",
       "   Outlet_Type_Supermarket Type3  Item_Identify_Type_DR  \\\n",
       "0                              0                      0   \n",
       "1                              0                      1   \n",
       "2                              0                      0   \n",
       "3                              0                      0   \n",
       "4                              0                      0   \n",
       "\n",
       "   Item_Identify_Type_FD  Item_Identify_Type_NC  \n",
       "0                      1                      0  \n",
       "1                      0                      0  \n",
       "2                      1                      0  \n",
       "3                      1                      0  \n",
       "4                      0                      1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.Item_Outlet_Sales\n",
    "data.drop('Item_Outlet_Sales',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.16774830e+01 -2.89148724e+02  1.55743028e+01 -9.74431543e+00\n",
      " -3.33438162e+01 -2.78735259e-01  8.55189736e+01 -1.74405401e+01\n",
      " -3.81639203e+00 -7.00710454e-01  3.70883394e+00  2.24970626e+01\n",
      " -5.30003569e+01 -3.06907822e+01  2.44007259e+01 -5.11773905e+01\n",
      "  7.43458433e+00 -2.09147499e+01 -3.62508671e+00 -3.96037456e+00\n",
      "  1.79593849e+02 -1.47834944e+01 -7.33699373e+01  1.84042192e+01\n",
      " -1.64578260e+03  1.79452196e+02 -2.47306981e+02  1.71363738e+03\n",
      "  3.01255098e+01 -1.26849697e+01 -1.74405401e+01]\n"
     ]
    }
   ],
   "source": [
    "print(regressor.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5629450976862653"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(data,y) #R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Split your data in 80% train set and 20% test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(data, y, train_size=0.8,test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Use grid_search to find the best value of the parameter `alpha` for Ridge and Lasso regressions from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_candidates = [\n",
    "  {'alpha': np.linspace(0.01, 0.02, 20)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso,Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(\n",
    "    degree = 2, include_bias = False, interaction_only = False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "polynomial_column_names = \\\n",
    "    poly.get_feature_names(input_features = X_train.columns)\n",
    "X_train_poly = \\\n",
    "    pd.DataFrame(data = X_train_poly, \n",
    "        columns = polynomial_column_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Fat_Content                               float64\n",
       "Item_Visibility                                float64\n",
       "Item_MRP                                       float64\n",
       "Outlet_Establishment_Year                      float64\n",
       "Outlet_Location_Type                           float64\n",
       "                                                ...   \n",
       "Item_Identify_Type_DR Item_Identify_Type_FD    float64\n",
       "Item_Identify_Type_DR Item_Identify_Type_NC    float64\n",
       "Item_Identify_Type_FD^2                        float64\n",
       "Item_Identify_Type_FD Item_Identify_Type_NC    float64\n",
       "Item_Identify_Type_NC^2                        float64\n",
       "Length: 527, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_poly.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly = poly.fit_transform(X_train)\n",
    "polynomial_column_names = \\\n",
    "    poly.get_feature_names(input_features = X_train.columns)\n",
    "X_train_poly = \\\n",
    "    pd.DataFrame(data = X_train_poly, \n",
    "        columns = polynomial_column_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "sc = StandardScaler()\n",
    "X_train_poly_scaled = sc.fit_transform(X_train_poly)\n",
    "X_train_poly_scaled = pd.DataFrame(data = X_train_poly_scaled, columns = X_train_poly.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do the same transform on test dat, no need to fit again\n",
    "X_test_poly = poly.transform(X_test)\n",
    "X_test_poly_scaled = sc.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import \\\n",
    "    r2_score, get_scorer\n",
    "scorer = get_scorer('r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso=Lasso(max_iter=3000)\n",
    "ridge=Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoreg = GridSearchCV(estimator=lasso, param_grid=parameter_candidates, n_jobs=-1, scoring ='r2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgereg=GridSearchCV(estimator=ridge, param_grid=parameter_candidates, n_jobs=-1, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2613886228.6952825, tolerance: 2015946.9941519697\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Lasso(max_iter=3000), n_jobs=-1,\n",
       "             param_grid=[{'alpha': array([0.01      , 0.01052632, 0.01105263, 0.01157895, 0.01210526,\n",
       "       0.01263158, 0.01315789, 0.01368421, 0.01421053, 0.01473684,\n",
       "       0.01526316, 0.01578947, 0.01631579, 0.01684211, 0.01736842,\n",
       "       0.01789474, 0.01842105, 0.01894737, 0.01947368, 0.02      ])}],\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoreg.fit(X_train_poly_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Ridge(), n_jobs=-1,\n",
       "             param_grid=[{'alpha': array([0.01      , 0.01052632, 0.01105263, 0.01157895, 0.01210526,\n",
       "       0.01263158, 0.01315789, 0.01368421, 0.01421053, 0.01473684,\n",
       "       0.01526316, 0.01578947, 0.01631579, 0.01684211, 0.01736842,\n",
       "       0.01789474, 0.01842105, 0.01894737, 0.01947368, 0.02      ])}],\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgereg.fit(X_train_poly_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for lasso: 0.5883887967990238\n"
     ]
    }
   ],
   "source": [
    "print('Best score for lasso:', lassoreg.best_score_) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for ridge: 0.5886496476187153\n"
     ]
    }
   ],
   "source": [
    "print('Best score for ridge:', ridgereg.best_score_) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for lasso: 0.02\n"
     ]
    }
   ],
   "source": [
    "print('Best alpha for lasso:',lassoreg.best_estimator_.alpha) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for ridge: 0.01\n"
     ]
    }
   ],
   "source": [
    "print('Best alpha for ridge:',ridgereg.best_estimator_.alpha) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regmodel_param_plot(\n",
    "    validation_score, train_score, alphas_to_try, chosen_alpha,\n",
    "    scoring, model_name, test_score = None, filename = None):\n",
    "    \n",
    "    plt.figure(figsize = (8,8))\n",
    "    sns.lineplot(y = validation_score, x = alphas_to_try, \n",
    "                 label = 'validation_data')\n",
    "    sns.lineplot(y = train_score, x = alphas_to_try, \n",
    "                 label = 'training_data')\n",
    "    plt.axvline(x=chosen_alpha, linestyle='--')\n",
    "    if test_score is not None:\n",
    "        sns.lineplot(y = test_score, x = alphas_to_try, \n",
    "                     label = 'test_data')\n",
    "    plt.xlabel('alpha_parameter')\n",
    "    plt.ylabel(scoring)\n",
    "    plt.title(model_name + ' Regularisation')\n",
    "    plt.legend()\n",
    "    if filename is not None:\n",
    "        plt.savefig(str(filename) + \".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def regmodel_param_test(\n",
    "    alphas_to_try, X, y, cv, scoring = 'r2', \n",
    "    model_name = 'LASSO', X_test = None, y_test = None, \n",
    "    draw_plot = False, filename = None):\n",
    "    \n",
    "    validation_scores = []\n",
    "    train_scores = []\n",
    "    results_list = []\n",
    "    if X_test is not None:\n",
    "        test_scores = []\n",
    "        scorer = get_scorer(scoring)\n",
    "    else:\n",
    "        test_scores = None\n",
    "\n",
    "    for curr_alpha in alphas_to_try:\n",
    "        \n",
    "        if model_name == 'LASSO':\n",
    "            regmodel = Lasso(alpha = curr_alpha)\n",
    "        elif model_name == 'Ridge':\n",
    "            regmodel = Ridge(alpha = curr_alpha)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        results = cross_validate(\n",
    "            regmodel, X, y, scoring=scoring, cv=cv, \n",
    "            return_train_score = True)\n",
    "\n",
    "        validation_scores.append(np.mean(results['test_score']))\n",
    "        train_scores.append(np.mean(results['train_score']))\n",
    "        results_list.append(results)\n",
    "\n",
    "        if X_test is not None:\n",
    "            regmodel.fit(X,y)\n",
    "            y_pred = regmodel.predict(X_test)\n",
    "            test_scores.append(scorer(regmodel, X_test, y_test))\n",
    "    \n",
    "    chosen_alpha_id = np.argmax(validation_scores)\n",
    "    chosen_alpha = alphas_to_try[chosen_alpha_id]\n",
    "    max_validation_score = np.max(validation_scores)\n",
    "    if X_test is not None:\n",
    "        test_score_at_chosen_alpha = test_scores[chosen_alpha_id]\n",
    "    else:\n",
    "        test_score_at_chosen_alpha = None\n",
    "        \n",
    "    if draw_plot:\n",
    "        regmodel_param_plot(\n",
    "            validation_scores, train_scores, alphas_to_try, chosen_alpha, \n",
    "            scoring, model_name, test_scores, filename)\n",
    "    \n",
    "    return chosen_alpha, max_validation_score, test_score_at_chosen_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not good, slightly more than baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Using the model from grid_search, predict the values in the test set and compare against your benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5987187825667534"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoreg.score(X_test_poly_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5993027826389071"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgereg.score(X_test_poly_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
